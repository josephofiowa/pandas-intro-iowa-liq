{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas for Exploratory Data Analysis II \n",
    "\n",
    "Recall Pandas is the most useful Python library for data manipulation and exploration. We have so much more to see!\n",
    "\n",
    "In this lesson, we'll continue exploring Pandas for EDA. Specifically: \n",
    "\n",
    "- Identify and handle missing values with Pandas.\n",
    "- Implement groupby statements for specific segmented analysis.\n",
    "- Use apply functions to clean data with Pandas.\n",
    "\n",
    "We'll implicitly review many functions from our first Pandas lesson along the way!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember the Iowa Liquor Dataset?\n",
    "\n",
    "- **Invoice/Item Number** - Concatenated invoice and line number associated with the liquor order. This provides a unique identifier for the individual liquor products included in the store order\n",
    "- **Date** - Date of order \n",
    "- **Store Number** - Unique number assigned to the store who ordered the liquor.\n",
    "- **Store Name** - Name of store who ordered the liquor.\n",
    "- **Address** - Address of the store that ordered the liquor\n",
    "- **City** - City where the store who ordered the liquor is located\n",
    "- **Zip Code** - Zip Code of where the store that ordered is located \n",
    "- **Store Location** - Location of store who ordered the liquor. The Address, City, State and Zip Code are geocoded to provide geographic coordinates. Accuracy of geocoding is dependent on how well the address is interpreted and the completeness of the reference data used.\n",
    "- **County Number** - Iowa county number for the county where store who ordered the liquor is located\n",
    "- **County** - County where the store who ordered the liquor is located\n",
    "- **Category** - Category code associated with the liquor ordered\n",
    "- **Category Names** - Category of the liquor ordered.\n",
    "- **Vendor Number** - The vendor number of the company for the brand of liquor ordered\n",
    "- **Vendor Name** - The vendor name of the company for the brand of liquor ordered\n",
    "- **Item Name** - Item number for the individual liquor product ordered.\n",
    "- **Item Description** - Description of the individual liquor product ordered.\n",
    "- **Pack** - The number of bottles in a case for the liquor ordered\n",
    "- **Bottle Volume (mL)** - Volume of each liquor bottle ordered in milliliters.\n",
    "- **State Bottle Cost** - The amount that Alcoholic Beverages Division paid for each bottle of liquor ordered\n",
    "- **State Bottle Retail** - The amount the store paid for each bottle of liquor ordered\n",
    "- **Bottles Solde** - The number of bottles of liquor ordered by the store\n",
    "- **Sale (Dollars)** - Total cost of liquor order (number of bottles multiplied by the state bottle retail)\n",
    "- **Volume Sold (Liters)** - Total volume of liquor ordered in liters. (i.e. (Bottle Volume (ml) x Bottles Sold)/1,000)\n",
    "- **Volume Sold (Gallons)** - Total volume of liquor ordered in gallons. (i.e. (Bottle Volume (ml) x Bottles Sold)/3785.411784)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Modified Iowa Liquor Dataset\n",
    "\n",
    "Because the full dataset (of all liquor sales from 2012 to present) is greater than 13 million rows (13,948,103+ at the time of writing), **we will work with a modified dataset.**\n",
    "\n",
    "Our modified dataset has a few key changes:\n",
    "- Only sales from May 2017 and May 2018 are present\n",
    "- A number of values have been deliberately deleted (to practice working with missing data!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # used for linear algebra and random sampling\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the dataset\n",
    "\n",
    "We are using the `read_csv()` method (and using a special encoding to handle our file's Excel roots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq = pd.read_csv(\"../data/iowa_liquor_may_17_18.csv\", encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember checking the top five rows\n",
    "liq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename our columns (like last time)\n",
    "\n",
    "Let's rename our columns so our data is easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare a list of strings - these strings will become the new column names\n",
    "cols = ['date', 'store_number', 'store_name', 'city', \n",
    "        'zip_code', 'location', 'county', 'category_name',\n",
    "        'vendor_name', 'item_number', 'item_description', 'pack', \n",
    "       'bottle_vol_ml', 'state_bottle_cost', 'state_bottle_retail', 'bottles_sold',\n",
    "       'sale', 'volumne_sold_l', 'volume_sold_gal', 'is_may_2017', 'is_may_2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing data\n",
    "\n",
    "Recall missing data is a systemic, challenging problem for data scientists. Imagine conducting a US election poll, but losing all female voter responses in the process!\n",
    "\n",
    "\"Handling missing data\" itself is a broad topic. We'll focus on two components:\n",
    "\n",
    "- Using Pandas to identify we have missing data\n",
    "- Strategies to fill in missing data\n",
    "- Filling in missing data with Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Create missing data*** ðŸ˜®\n",
    "\n",
    "> For the purposes of education... Run the below cell to *create* missing data in our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random places to drop data\n",
    "to_drop1 = np.random.randint(1,427923,72746)\n",
    "to_drop2 = np.random.randint(1,427923,29954)\n",
    "np.append(to_drop2, 2) # make sure we have index number 2 to drop\n",
    "\n",
    "\n",
    "# drop the data!!!\n",
    "liq.iloc[to_drop1,15] = np.nan\n",
    "liq.iloc[to_drop2,16] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying missing data\n",
    "\n",
    "Before *handling*, we must identify we're missing data at all! (In this given dataset, we have eliminated datapoints for the purposes of these exercises.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a few ways to explore missing data, and they are reminiscient of our Boolean filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True when data isn't missing\n",
    "liq.notnull() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True when data is missing\n",
    "liq.isnull() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we may want to see null values in aggregate. We can use `sum()` to sum down a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see number of missing values per column\n",
    "liq.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look! We've found missing values!\n",
    "\n",
    "How could this missing data be problematic for our analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding missing data\n",
    "\n",
    "Finding missing data is the easy part! Determining way to do next is more complicated.\n",
    "\n",
    "Typically, we are most interested in knowing **why** we are missing data. Once we know what 'type of missingness' we have (the source of missing data), we can proceed effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first quantify how much data we are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a boolean filter to only show rows where bottles_sold is missing\n",
    "liq[liq.bottles_sold.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain just the number of rows\n",
    "liq[liq.bottles_sold.isnull()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide this by the overall DataFrame to get a percent of missing values\n",
    "liq[liq.bottles_sold.isnull()].shape[0] / liq.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for `sale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq[liq.sale.isnull()].shape[0] / liq.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collectively, we are missing about 16% of data on the number of bottles sold in a given daily transaction, and about 7% of the data on total sale value for a given number of items in a single day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in missing data\n",
    "\n",
    "How we fill in data depends largely on why it is missing (types of missingness) and what sampling we have available to us.\n",
    "\n",
    "We may:\n",
    "\n",
    "- Delete missing data altogether\n",
    "- Fill in missing data with:\n",
    "    - The average of the column\n",
    "    - The median of the column\n",
    "    - A predicted amount based on other factors\n",
    "- Collect more data:\n",
    "    - Resample the population\n",
    "    - Followup with the authority providing data that is missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, let's focus on handling `bottles_sold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we identify a pattern of missingness (no)\n",
    "liq[liq.bottles_sold.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the missing values have a significantly different five number summary than non-missing?\n",
    "liq[liq.bottles_sold.isnull()].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset 5-number summary\n",
    "liq.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the difference between the two\n",
    "liq.describe() - liq[liq.bottles_sold.isnull()].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears the two samples do not have *significant* differences! (We could run statistical tests, but...another day.)\n",
    "\n",
    "Now, this makes sense! We did randomly drop values, afterall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: Drop the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops rows where any row has a missing value - this does not happen *in place*, so we are not actually dropping\n",
    "liq.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: Fill in missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditionally, we fill missing data with a median, average, or modelled value. Let's see the five-number-summary of the column of interest to decide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq.bottles_sold.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this given case, we may opt to fill our data in with the *median* (50%) rather than the *mean* because we see such a positive skew. The most commonly processed transaction is on bottles that are single order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 50th percentile\n",
    "liq.bottles_sold.quantile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing data with 50th percentile -- note we *are* making this change in place\n",
    "liq.bottles_sold.fillna(value=liq.bottles_sold.quantile(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check total number of missing values\n",
    "liq.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're gone!\n",
    "\n",
    "Now, to be fair, we may want to investigate our missing values *even more*! What if counties with larger orders, on balance, are more likely to be missing from our dataset? This would skew our data unfairly.\n",
    "\n",
    "Even determining how to fill in missing data requires careful exploratory data analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby Statements\n",
    "\n",
    "In Pandas, groupby statements are similar to pivot tables in that they allow us to segment our population to a specific subset.\n",
    "\n",
    "For example, if we want to know the average number of bottles sold and pack sizes per city, a groupby statement would make this task much more straightforward.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To think how a groupby statement works, think about it like this:\n",
    "\n",
    "- **Split:** Separate our DataFrame by a specific attribute\n",
    "- **Apply:** Determine how categories are going to be mathematically incorporated. For example, if there are multiple store locations in one city, do we want the average amount across all stores, the total amount for the stores, or perhaps even the highest amount for a single store per city?\n",
    "- **Combine:** Put our DataFrame back together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i.imgur.com/yjNkiwL.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby city - take the average for each column when combining back together\n",
    "liq.groupby('city').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perhaps we want *just* bottles sold from the above\n",
    "liq.groupby('city').bottles_sold.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or maybe, we want the biggest single transaction per county\n",
    "liq.groupby('city').bottles_sold.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in fact, we can 'apply' a mean and max at once- plus count and min!\n",
    "liq.groupby('city').bottles_sold.agg(['count', 'mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by largest average; grab top 10 cities in Iowa by average liquor store bottle size purchase\n",
    "liq.groupby('city').bottles_sold.agg(['count', 'mean', 'min', 'max']).sort_values(by='mean', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby creates a groupby object - it needs to be told how to aggregate things together\n",
    "liq.groupby('city').bottles_sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq.groupby('city').bottles_sold.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 cities by counts of active liquor stores\n",
    "liq.groupby('city').bottles_sold.count().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply functions for column operations\n",
    "\n",
    "Apply functions allow us to perform a complex operation across an entire columns highly efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, recall our `sale` data is formatted in an unhelpful way (strings, not floats):                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first sale value\n",
    "liq.sale[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert this value to a float, and without the dollar sign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply functions** allow us to write a function that cleans a single value, and then we *apply* that function to a whole column. (It's like a for loop, but way more efficient as an operation!)\n",
    "\n",
    "Writing them follows a familiar three steps:\n",
    "\n",
    "1. Write a function that creates the desired output on a single value\n",
    "2. Test that function on one value of interest\n",
    "3. Apply that function to the whole column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's write a function that converts an inputted value with a dollar sign to a float, and returns that float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dollars_to_float(value):\n",
    "    \n",
    "    # try to convert the inputted value to a float\n",
    "    try:\n",
    "        return float(value.strip('$'))\n",
    "    \n",
    "    # in the case of the value being a null value, we simply return a null\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our function on a value of interest or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq.sale[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq.sale[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollars_to_float(liq.sale[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollars_to_float(liq.sale[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we apply this function to the whole column with the following syntax. Notice: we are going to create a new column (out of thin air!) called `sale_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq['sale_clean'] = liq.sale.apply(dollars_to_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! Our first apply function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn:** Identify one other column where we may want to write a new apply function, or use the one we just created for the purposes of cleaning up our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify a column to fix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to fix a single value in that columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply that function across the whole column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap up\n",
    "\n",
    "We've covered even more useful information! Here are the key takeaways:\n",
    "\n",
    "- **Missing data** comes in many shapes and sizes. Before deciding how to handle it, we identify it exists. We then derive how the missingness is affecting our dataset, and make a determination about how to fill in values.\n",
    "\n",
    "```python\n",
    "# pro tip for identifying missing data\n",
    "df.isnull().sum()\n",
    "```\n",
    "\n",
    "- **Grouby** statements are particularly useful for a subsection-of-interest analysis. Specifically, zooming in on one condition, and determining relevant statstics.\n",
    "\n",
    "```python\n",
    "# group by \n",
    "df.groupby('column').agg['count', 'mean', 'max', 'min']\n",
    "```\n",
    "\n",
    "- **Apply functions** help us clean values across an entire DataFrame column. They are *like* a for loop for cleaning, but many times more efficient. They follow a common pattern:\n",
    "1. Write a function that works on a single value\n",
    "2. Test that function on a single value\n",
    "3. Apply that function to a whole column\n",
    "\n",
    "(The most confusing part of apply functions is that we write them with *a single value* in mind, and then apply them to many single values at once.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
